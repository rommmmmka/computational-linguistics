{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-01T12:47:37.913899500Z",
     "start_time": "2024-05-01T12:47:34.753702Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 15:47:38 INFO: Loading these models for language: be (Belarusian):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | hse          |\n",
      "| pos       | hse_nocharlm |\n",
      "| lemma     | hse_nocharlm |\n",
      "============================\n",
      "\n",
      "2024-05-01 15:47:38 INFO: Using device: cpu\n",
      "2024-05-01 15:47:38 INFO: Loading: tokenize\n",
      "2024-05-01 15:47:40 INFO: Loading: pos\n",
      "2024-05-01 15:47:40 INFO: Loading: lemma\n",
      "2024-05-01 15:47:40 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza_analyzer = stanza.Pipeline(\n",
    "    lang=\"be\",\n",
    "    processors=\"tokenize,pos,lemma\",\n",
    "    download_method=stanza.DownloadMethod.REUSE_RESOURCES\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T12:47:40.481572600Z",
     "start_time": "2024-05-01T12:47:37.919203500Z"
    }
   },
   "id": "1d12a08a6718fa8a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BANNED_SYMBOLS = \"abcdefghijklmnopqrstuvwxyzищъ\"\n",
    "BANNED_POS = [\"PUNCT\", \"SYM\", \"X\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T12:47:40.495508400Z",
     "start_time": "2024-05-01T12:47:40.474210400Z"
    }
   },
   "id": "f0732632ce6682ad"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results\\texts\\01.txt | sentences: 12865 | words: 111642\n",
      "results\\texts\\02.txt | sentences: 1143  | words: 5384\n",
      "results\\texts\\03.txt | sentences: 612   | words: 9597\n",
      "results\\texts\\04.txt | sentences: 6196  | words: 80911\n",
      "results\\texts\\05.txt | sentences: 1892  | words: 21174\n",
      "results\\texts\\06.txt | sentences: 1314  | words: 28022\n",
      "results\\texts\\07.txt | sentences: 1983  | words: 28287\n",
      "results\\texts\\08.txt | sentences: 965   | words: 14301\n",
      "results\\texts\\09.txt | sentences: 2335  | words: 27301\n",
      "results\\texts\\10.txt | sentences: 4147  | words: 46929\n",
      "results\\texts\\11.txt | sentences: 9244  | words: 63851\n",
      "results\\texts\\12.txt | sentences: 3083  | words: 28372\n",
      "results\\texts\\13.txt | sentences: 3893  | words: 42875\n",
      "results\\texts\\14.txt | sentences: 6835  | words: 82240\n",
      "results\\texts\\15.txt | sentences: 2478  | words: 31969\n",
      "results\\texts\\16.txt | sentences: 8600  | words: 89304\n",
      "results\\texts\\17.txt | sentences: 1905  | words: 25790\n",
      "results\\texts\\18.txt | sentences: 3279  | words: 36618\n",
      "results\\texts\\19.txt | sentences: 3169  | words: 39899\n",
      "results\\texts\\20.txt | sentences: 2783  | words: 35706\n",
      "results\\texts\\21.txt | sentences: 4409  | words: 48870\n",
      "results\\texts\\22.txt | sentences: 130   | words: 1782\n",
      "results\\texts\\23.txt | sentences: 7890  | words: 88318\n",
      "results\\texts\\24.txt | sentences: 8235  | words: 86395\n",
      "results\\texts\\25.txt | sentences: 8486  | words: 88248\n",
      "results\\texts\\26.txt | sentences: 6381  | words: 67608\n",
      "results\\texts\\27.txt | sentences: 5423  | words: 50867\n",
      "results\\texts\\28.txt | sentences: 4615  | words: 58396\n",
      "results\\texts\\29.txt | sentences: 9916  | words: 125567\n",
      "results\\texts\\30.txt | sentences: 9731  | words: 141607\n",
      "results\\texts\\31.txt | sentences: 27298 | words: 215809\n",
      "results\\texts\\32.txt | sentences: 17470 | words: 132775\n",
      "results\\texts\\33.txt | sentences: 12986 | words: 101741\n",
      "results\\texts\\34.txt | sentences: 5663  | words: 58791\n",
      "results\\texts\\35.txt | sentences: 3588  | words: 27689\n",
      "results\\texts\\36.txt | sentences: 1340  | words: 10656\n",
      "results\\texts\\37.txt | sentences: 2903  | words: 24058\n",
      "results\\texts\\38.txt | sentences: 2239  | words: 19100\n",
      "results\\texts\\39.txt | sentences: 4428  | words: 31231\n",
      "results\\texts\\40.txt | sentences: 559   | words: 4317\n",
      "results\\texts\\41.txt | sentences: 18307 | words: 199200\n",
      "results\\texts\\42.txt | sentences: 1311  | words: 16808\n",
      "results\\texts\\43.txt | sentences: 1987  | words: 20535\n",
      "results\\texts\\44.txt | sentences: 4806  | words: 46514\n",
      "results\\texts\\45.txt | sentences: 3309  | words: 36035\n",
      "results\\texts\\46.txt | sentences: 530   | words: 4602\n",
      "results\\texts\\47.txt | sentences: 12388 | words: 109872\n",
      "results\\texts\\48.txt | sentences: 11053 | words: 90232\n",
      "results\\texts\\49.txt | sentences: 8069  | words: 64126\n",
      "results\\texts\\50.txt | sentences: 1073  | words: 11425\n",
      "results\\texts\\51.txt | sentences: 4784  | words: 30246\n",
      "results\\texts\\52.txt | sentences: 988   | words: 12013\n",
      "results\\texts\\53.txt | sentences: 26558 | words: 239553\n",
      "results\\texts\\54.txt | sentences: 603   | words: 7385\n",
      "results\\texts\\55.txt | sentences: 3804  | words: 13225\n",
      "results\\texts\\56.txt | sentences: 529   | words: 4940\n",
      "results\\texts\\57.txt | sentences: 6090  | words: 67995\n",
      "results\\texts\\58.txt | sentences: 6647  | words: 81900\n",
      "results\\texts\\59.txt | sentences: 4942  | words: 60304\n",
      "results\\texts\\60.txt | sentences: 6252  | words: 97229\n",
      "results\\texts\\61.txt | sentences: 4650  | words: 36504\n",
      "results\\texts\\62.txt | sentences: 558   | words: 5501\n",
      "results\\texts\\63.txt | sentences: 334   | words: 5576\n",
      "results\\texts\\64.txt | sentences: 478   | words: 4231\n",
      "results\\texts\\65.txt | sentences: 185   | words: 2065\n",
      "results\\texts\\66.txt | sentences: 271   | words: 4023\n",
      "results\\texts\\67.txt | sentences: 111   | words: 2094\n",
      "results\\texts\\68.txt | sentences: 430   | words: 4802\n",
      "results\\texts\\69.txt | sentences: 143   | words: 2904\n",
      "results\\texts\\70.txt | sentences: 5265  | words: 58361\n",
      "results\\texts\\71.txt | sentences: 2185  | words: 21497\n",
      "results\\texts\\72.txt | sentences: 7793  | words: 70890\n",
      "results\\texts\\73.txt | sentences: 1663  | words: 17944\n",
      "results\\texts\\74.txt | sentences: 2748  | words: 26223\n",
      "results\\texts\\75.txt | sentences: 7181  | words: 99652\n",
      "results\\texts\\76.txt | sentences: 7201  | words: 89385\n",
      "results\\texts\\77.txt | sentences: 16382 | words: 124269\n",
      "results\\texts\\78.txt | sentences: 15132 | words: 104516\n",
      "results\\texts\\79.txt | sentences: 6353  | words: 49217\n",
      "results\\texts\\80.txt | sentences: 5829  | words: 65050\n",
      "----------\n",
      "Overall:\n",
      "----------\n",
      "Sentences: 431333\n",
      "Words: 4242840\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "for filename in os.scandir(\"results\\\\texts\"):\n",
    "    if not filename.is_file():\n",
    "        continue\n",
    "        \n",
    "    print(filename.path, end=\"\")\n",
    "    with open(filename.path, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        doc = stanza_analyzer(file.read())\n",
    "        \n",
    "        sentences_count = 0\n",
    "        words_count = 0\n",
    "        for sentence in doc.sentences:\n",
    "            if any(char in BANNED_SYMBOLS for char in sentence.text.lower()):\n",
    "                continue\n",
    "                \n",
    "            sentence_arr = []\n",
    "            for word in sentence.words:\n",
    "                if word.upos not in BANNED_POS:\n",
    "                    sentence_arr.append(word.lemma) \n",
    "                    words_count += 1\n",
    "                \n",
    "            if len(sentence_arr) != 0:\n",
    "                sentences.append(sentence_arr)\n",
    "                sentences_count += 1\n",
    "                \n",
    "        print(f\" | sentences: {sentences_count:<5} | words: {words_count}\")\n",
    "        \n",
    "with open(\"results/sentences.json\", mode=\"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\n",
    "        json.dumps(sentences, ensure_ascii=False)\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"----------\\n\"\n",
    "    f\"Overall:\\n\"\n",
    "    f\"----------\\n\"\n",
    "    f\"Sentences: {len(sentences)}\\n\"\n",
    "    f\"Words: {sum(map(len, sentences))}\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T14:39:34.900381100Z",
     "start_time": "2024-05-01T12:47:40.492377400Z"
    }
   },
   "id": "221e5c998cf61185"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
